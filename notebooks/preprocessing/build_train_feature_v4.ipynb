{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Train Feature Table V4 (Strategic Features)\n",
    "\n",
    "이 노트북은 `kkbox_train_feature_v3.parquet`를 기반으로, 모델 보고서에서 제안된 **전략적 파생 변수(Strategic Derived Features)**를 추가하여 V4 데이터셋을 생성합니다.\n",
    "\n",
    "## 추가되는 피처 (New Features)\n",
    "1. **`active_decay_rate`**: 최근 활동 감소율 (w7 vs w30)\n",
    "2. **`listening_time_velocity`**: 청취 시간 가속도 (w7 - w14)\n",
    "3. **`discovery_index`**: 탐색 지수 (Unique 곡 비중)\n",
    "4. **`skip_passion_index`**: 스킵 열정도 (25% 미만 / 100% 청취)\n",
    "5. **`last_active_gap`**: 마지막 접속 경과일 (잠수 유저 포착) - *Raw Log 처리 필요*\n",
    "6. **`daily_listening_variance`**: 청취 루틴 안정성 -> 기존 `std_secs_w7` 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로 설정\n",
    "if os.getcwd().endswith(\"preprocess\"):\n",
    "    os.chdir(\"../..\")\n",
    "    \n",
    "DATA_DIR = \"data/processed\"\n",
    "RAW_DATA_DIR = \"data/raw\"\n",
    "V3_PATH = os.path.join(DATA_DIR, \"kkbox_train_feature_v3.parquet\")\n",
    "USER_LOGS_PATH = os.path.join(RAW_DATA_DIR, \"user_logs_v2.csv\")\n",
    "OUTPUT_PATH = os.path.join(DATA_DIR, \"kkbox_train_feature_v4.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading V3 Data...\")\n",
    "df_v3 = pd.read_parquet(V3_PATH)\n",
    "print(f\"V3 Shape: {df_v3.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. V3 기반 파생 변수 생성 (Arithmetic Derived Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v4 = df_v3.copy()\n",
    "\n",
    "# 1. Active Decay Rate (활동 감소율)\n",
    "# Logic: (w7 active days) / (w30 active days / 4). If w30 is 0, set to 0 (or 1? 0 means no activity).\n",
    "# epsilon to avoid division by zero\n",
    "epsilon = 1e-6\n",
    "df_v4['active_decay_rate'] = df_v4['num_days_active_w7'] / ((df_v4['num_days_active_w30'] / 4) + epsilon)\n",
    "\n",
    "# 2. Listening Time Velocity (청취 가속도)\n",
    "# Logic: w7 avg secs - w14 avg secs\n",
    "df_v4['listening_time_velocity'] = df_v4['avg_secs_per_day_w7'] - df_v4['avg_secs_per_day_w14']\n",
    "\n",
    "# 3. Discovery Index (탐색 지수)\n",
    "# Logic: num_unq_w7 / num_songs_w7\n",
    "df_v4['discovery_index'] = df_v4['num_unq_w7'] / (df_v4['num_songs_w7'] + epsilon)\n",
    "\n",
    "# 4. Skip Passion Index (스킵 열정도)\n",
    "# Logic: num_25_w7 / num_100_w7\n",
    "df_v4['skip_passion_index'] = df_v4['num_25_w7'] / (df_v4['num_100_w7'] + epsilon)\n",
    "\n",
    "# 5. Daily Listening Variance (Renaming existing feature for clarity)\n",
    "df_v4['daily_listening_variance'] = df_v4['std_secs_w7']\n",
    "\n",
    "# 6. Engagement Density (몰입 밀도)\n",
    "# Logic: total_secs_w7 / num_days_active_w7. Note: This assumes avg_secs_per_day_w7 is calculated this way.\n",
    "# Let's create it explicitly to be sure.\n",
    "df_v4['engagement_density'] = df_v4['total_secs_w7'] / (df_v4['num_days_active_w7'] + epsilon)\n",
    "\n",
    "print(\"Derived features created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Raw Log 기반 피처 생성 (Last Active Gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processing Raw User Logs for Last Active Gap...\")\n",
    "# user_logs_v2.csv is large, read necessary columns only\n",
    "chunks = pd.read_csv(USER_LOGS_PATH, usecols=['msno', 'date'], chunksize=1000000)\n",
    "\n",
    "last_active_df = pd.DataFrame()\n",
    "\n",
    "# Find max date per user in chunks\n",
    "max_dates = []\n",
    "for chunk in chunks:\n",
    "    chunk_max = chunk.groupby('msno')['date'].max()\n",
    "    max_dates.append(chunk_max)\n",
    "\n",
    "# Combine and find global max per user\n",
    "all_max_dates = pd.concat(max_dates)\n",
    "final_last_active = all_max_dates.groupby(level=0).max().reset_index()\n",
    "final_last_active.rename(columns={'date': 'last_active_date'}, inplace=True)\n",
    "\n",
    "# Convert to datetime\n",
    "final_last_active['last_active_date'] = pd.to_datetime(final_last_active['last_active_date'], format='%Y%m%d')\n",
    "\n",
    "print(f\"Max Active Dates Calculated. Users: {len(final_last_active)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine Study Cutoff Date\n",
    "# The training data (v3) is likely based on a specific month (e.g., March 2017).\n",
    "# Let's check the max date in the logs to be consistent, or assume the end of the logs is the cutoff.\n",
    "global_max_date = final_last_active['last_active_date'].max()\n",
    "print(f\"Global Max Date in Logs: {global_max_date}\")\n",
    "\n",
    "# Calculate Gap\n",
    "final_last_active['last_active_gap'] = (global_max_date - final_last_active['last_active_date']).dt.days\n",
    "\n",
    "print(final_last_active[['msno', 'last_active_gap']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with V4 DataFrame\n",
    "df_v4 = df_v4.merge(final_last_active[['msno', 'last_active_gap']], on='msno', how='left')\n",
    "\n",
    "# Fill NA for users with no logs (unlikely if they are in train set, but possible)\n",
    "# If no log, gap is large number?? or -1?\n",
    "# Assign a large number (e.g., 999) or the max gap found\n",
    "max_gap_found = df_v4['last_active_gap'].max()\n",
    "df_v4['last_active_gap'] = df_v4['last_active_gap'].fillna(max_gap_found + 1)\n",
    "\n",
    "print(\"Merged Last Active Gap.\")\n",
    "print(df_v4[['msno', 'last_active_gap']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 저장 (Save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Saving V4 to {OUTPUT_PATH}...\")\n",
    "df_v4.to_parquet(OUTPUT_PATH, index=False)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Features\n",
    "print(\"New Feature Statistics:\")\n",
    "new_cols = ['active_decay_rate', 'listening_time_velocity', 'discovery_index', 'skip_passion_index', 'last_active_gap']\n",
    "print(df_v4[new_cols].describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
