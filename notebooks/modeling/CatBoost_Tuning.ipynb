{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost Hyperparameter Tuning (Optuna)\n",
    "\n",
    "이 노트북은 전처리된 데이터를 기반으로 CatBoost 모델의 하이퍼파라미터를 튜닝하고 최적의 모델을 저장합니다.\n",
    "\n",
    "**목표**:\n",
    "- Optuna를 사용한 하이퍼파라미터 최적화\n",
    "- 최적화 지표: **F1-Score** (User Request)\n",
    "- Best Model 저장 및 메타데이터 기록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "import json\n",
    "import os\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(860966, 92)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "train_path = '../data/processed/kkbox_train_feature_v4.parquet'\n",
    "df = pd.read_parquet(train_path)\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: 88\n",
      "Categorical: 8\n",
      "Numerical: 80\n"
     ]
    }
   ],
   "source": [
    "RANDOM_STATE = 719\n",
    "ID_COL = \"msno\"\n",
    "TARGET_COL = \"is_churn\"\n",
    "\n",
    "# 범주형 및 수치형 컬럼 정의 (이전 노트북 참조)\n",
    "CATEGORICAL_COLS = [\n",
    "    \"city\", \"gender\", \"registered_via\", \"last_payment_method\",\n",
    "    \"has_ever_paid\", \"has_ever_cancelled\",\n",
    "    \"is_auto_renew_last\",\n",
    "    \"is_free_user\",\n",
    "]\n",
    "\n",
    "NUMERICAL_COLS = [\n",
    "    \"reg_days\",\n",
    "    # w7\n",
    "    \"num_days_active_w7\", \"total_secs_w7\", \"avg_secs_per_day_w7\", \"std_secs_w7\",\n",
    "    \"num_songs_w7\", \"avg_songs_per_day_w7\", \"num_unq_w7\", \"num_25_w7\", \"num_100_w7\",\n",
    "    \"short_play_w7\", \"skip_ratio_w7\", \"completion_ratio_w7\", \"short_play_ratio_w7\", \"variety_ratio_w7\",\n",
    "    # w14\n",
    "    \"num_days_active_w14\", \"total_secs_w14\", \"avg_secs_per_day_w14\", \"std_secs_w14\",\n",
    "    \"num_songs_w14\", \"avg_songs_per_day_w14\", \"num_unq_w14\", \"num_25_w14\", \"num_100_w14\",\n",
    "    \"short_play_w14\", \"skip_ratio_w14\", \"completion_ratio_w14\", \"short_play_ratio_w14\", \"variety_ratio_w14\",\n",
    "    # w21\n",
    "    \"num_days_active_w21\", \"total_secs_w21\", \"avg_secs_per_day_w21\", \"std_secs_w21\",\n",
    "    \"num_songs_w21\", \"avg_songs_per_day_w21\", \"num_unq_w21\", \"num_25_w21\", \"num_100_w21\",\n",
    "    \"short_play_w21\", \"skip_ratio_w21\", \"completion_ratio_w21\", \"short_play_ratio_w21\", \"variety_ratio_w21\",\n",
    "    # w30 (Excluded)\n",
    "    \"num_days_active_w30\", \"total_secs_w30\", \"avg_secs_per_day_w30\", \"std_secs_w30\",\n",
    "    \"num_songs_w30\", \"avg_songs_per_day_w30\", \"num_unq_w30\", \"num_25_w30\", \"num_100_w30\",\n",
    "    \"short_play_w30\", \"skip_ratio_w30\", \"completion_ratio_w30\", \"short_play_ratio_w30\", \"variety_ratio_w30\",\n",
    "    # trends\n",
    "    \"days_trend_w7_w14\",\n",
    "    \"secs_trend_w7_w30\", \"secs_trend_w14_w30\",\n",
    "    \"days_trend_w7_w30\",\n",
    "    \"songs_trend_w7_w30\", \"songs_trend_w14_w30\",\n",
    "    \"skip_trend_w7_w30\", \"completion_trend_w7_w30\",\n",
    "    # transactions\n",
    "    \"days_since_last_payment\", \"days_since_last_cancel\", \"last_plan_days\",\n",
    "    \"total_payment_count\", \"total_amount_paid\", \"avg_amount_per_payment\",\n",
    "    \"unique_plan_count\", \"subscription_months_est\",\n",
    "    \"payment_count_last_30d\", \"payment_count_last_90d\",\n",
    "    # V4 New Derived Features\n",
    "    \"active_decay_rate\",\n",
    "    \"listening_time_velocity\",\n",
    "    \"discovery_index\",\n",
    "    \"skip_passion_index\",\n",
    "    \"last_active_gap\"\n",
    "]\n",
    "\n",
    "# 실제 데이터프레임에 존재하는 컬럼만 필터링\n",
    "cat_cols = [c for c in CATEGORICAL_COLS if c in df.columns]\n",
    "num_cols = [c for c in NUMERICAL_COLS if c in df.columns]\n",
    "FEATURE_COLS = cat_cols + num_cols\n",
    "\n",
    "print(f\"Selected Features: {len(FEATURE_COLS)}\")\n",
    "print(f\"Categorical: {len(cat_cols)}\")\n",
    "print(f\"Numerical: {len(num_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing & Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (688772, 88)\n",
      "Valid shape: (172194, 88)\n"
     ]
    }
   ],
   "source": [
    "# CatBoost 처리를 위해 범주형 변수를 문자열로 변환\n",
    "for col in cat_cols:\n",
    "    df[col] = df[col].astype(str).astype(\"category\")\n",
    "\n",
    "X = df[FEATURE_COLS]\n",
    "y = df[TARGET_COL].astype(int)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}\")\n",
    "print(f\"Valid shape: {X_valid.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Optuna Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"iterations\": trial.suggest_int(\"iterations\", 1000, 3000),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 4, 10),\n",
    "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1, 10, log=True),\n",
    "        \"border_count\": trial.suggest_int(\"border_count\", 32, 255),\n",
    "        \"random_strength\": trial.suggest_float(\"random_strength\", 1e-9, 10, log=True),\n",
    "        \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0, 1),\n",
    "        \"auto_class_weights\": \"Balanced\",  # 불균형 데이터 처리\n",
    "        \"loss_function\": \"Logloss\",\n",
    "        \"eval_metric\": \"F1\",  # Optuna 내부 평가용 (CatBoost metric)\n",
    "        \"random_seed\": RANDOM_STATE,\n",
    "        \"verbose\": False,\n",
    "        \"early_stopping_rounds\": 100,\n",
    "    }\n",
    "\n",
    "    model = CatBoostClassifier(**params)\n",
    "    \n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        cat_features=cat_cols,\n",
    "        eval_set=(X_valid, y_valid),\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # F1 Score 계산 (Threshold 0.5 기준, 필요 시 튜닝 가능하지만 일단 0.5 고정)\n",
    "    y_pred = model.predict(X_valid)\n",
    "    score = f1_score(y_valid, y_pred)\n",
    "    \n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fd14d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-21 06:22:55,045] A new study created in memory with name: no-name-d16bd586-83ea-475a-8c1a-5c0cdd836d17\n",
      "[I 2025-12-21 06:25:09,302] Trial 0 finished with value: 0.7983366895938488 and parameters: {'iterations': 2114, 'learning_rate': 0.013856872052279152, 'depth': 5, 'l2_leaf_reg': 2.6759351522412134, 'border_count': 192, 'random_strength': 3.191775654000403e-06, 'bagging_temperature': 0.9707390406500667}. Best is trial 0 with value: 0.7983366895938488.\n",
      "[I 2025-12-21 06:27:00,992] Trial 1 finished with value: 0.7909036753088659 and parameters: {'iterations': 2357, 'learning_rate': 0.012709389225120807, 'depth': 4, 'l2_leaf_reg': 4.304304094310822, 'border_count': 160, 'random_strength': 2.814513498196936e-06, 'bagging_temperature': 0.03435881846082345}. Best is trial 0 with value: 0.7983366895938488.\n",
      "[I 2025-12-21 06:27:49,929] Trial 2 finished with value: 0.8023332194750257 and parameters: {'iterations': 1627, 'learning_rate': 0.09317293864262122, 'depth': 5, 'l2_leaf_reg': 1.1918685919324714, 'border_count': 131, 'random_strength': 0.0433732356742916, 'bagging_temperature': 0.4268712170600809}. Best is trial 2 with value: 0.8023332194750257.\n",
      "[I 2025-12-21 06:30:39,688] Trial 3 finished with value: 0.8024525670377095 and parameters: {'iterations': 2828, 'learning_rate': 0.0050026515194664485, 'depth': 8, 'l2_leaf_reg': 1.0188436521315694, 'border_count': 134, 'random_strength': 0.0045044770810892835, 'bagging_temperature': 0.45756810496988165}. Best is trial 3 with value: 0.8024525670377095.\n",
      "[I 2025-12-21 06:32:48,378] Trial 4 finished with value: 0.7908300558890499 and parameters: {'iterations': 2987, 'learning_rate': 0.009231107565373719, 'depth': 5, 'l2_leaf_reg': 2.9802785471061015, 'border_count': 253, 'random_strength': 4.5216596127816356e-05, 'bagging_temperature': 0.9879639946875977}. Best is trial 3 with value: 0.8024525670377095.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value: 0.8024525670377095\n",
      "  Params: \n",
      "    iterations: 2828\n",
      "    learning_rate: 0.0050026515194664485\n",
      "    depth: 8\n",
      "    l2_leaf_reg: 1.0188436521315694\n",
      "    border_count: 134\n",
      "    random_strength: 0.0045044770810892835\n",
      "    bagging_temperature: 0.45756810496988165\n"
     ]
    }
   ],
   "source": [
    "# Optuna Study 실행\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=5)  # 시간 관계상 20회 시도 (필요 시 늘릴 것)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"  Value: {trial.value}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Best Model & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9289076\ttest: 0.9271706\tbest: 0.9271706 (0)\ttotal: 212ms\tremaining: 9m 59s\n",
      "100:\tlearn: 0.9317958\ttest: 0.9305034\tbest: 0.9305589 (36)\ttotal: 17.2s\tremaining: 7m 45s\n",
      "200:\tlearn: 0.9337117\ttest: 0.9334254\tbest: 0.9334285 (199)\ttotal: 34.5s\tremaining: 7m 30s\n",
      "300:\tlearn: 0.9347919\ttest: 0.9345586\tbest: 0.9346075 (282)\ttotal: 50.7s\tremaining: 7m 5s\n",
      "400:\tlearn: 0.9359643\ttest: 0.9358166\tbest: 0.9358585 (398)\ttotal: 1m 6s\tremaining: 6m 45s\n",
      "500:\tlearn: 0.9422506\ttest: 0.9424087\tbest: 0.9424378 (498)\ttotal: 1m 22s\tremaining: 6m 25s\n",
      "600:\tlearn: 0.9448261\ttest: 0.9452615\tbest: 0.9452707 (598)\ttotal: 1m 40s\tremaining: 6m 13s\n",
      "700:\tlearn: 0.9451794\ttest: 0.9457115\tbest: 0.9457238 (698)\ttotal: 1m 57s\tremaining: 5m 56s\n",
      "800:\tlearn: 0.9455066\ttest: 0.9460654\tbest: 0.9461074 (757)\ttotal: 2m 14s\tremaining: 5m 40s\n",
      "900:\tlearn: 0.9459672\ttest: 0.9465675\tbest: 0.9465737 (898)\ttotal: 2m 31s\tremaining: 5m 24s\n",
      "1000:\tlearn: 0.9462652\ttest: 0.9464061\tbest: 0.9466544 (913)\ttotal: 2m 48s\tremaining: 5m 6s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.9466544405\n",
      "bestIteration = 913\n",
      "\n",
      "Shrink model to first 914 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x148473da0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = study.best_params.copy()\n",
    "\n",
    "# 고정 파라미터 추가\n",
    "best_params.update({\n",
    "    \"loss_function\": \"Logloss\",\n",
    "    \"eval_metric\": \"F1\",\n",
    "    \"auto_class_weights\": \"Balanced\",\n",
    "    \"random_seed\": RANDOM_STATE,\n",
    "    \"verbose\": 100,\n",
    "    \"early_stopping_rounds\": 100,\n",
    "})\n",
    "\n",
    "final_model = CatBoostClassifier(**best_params)\n",
    "\n",
    "final_model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_cols,\n",
    "    eval_set=(X_valid, y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final F1 Score: 0.8024525670377095\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98    155904\n",
      "           1       0.70      0.94      0.80     16290\n",
      "\n",
      "    accuracy                           0.96    172194\n",
      "   macro avg       0.85      0.95      0.89    172194\n",
      "weighted avg       0.97      0.96      0.96    172194\n",
      "\n",
      "Confusion Matrix:\n",
      " [[149440   6464]\n",
      " [  1043  15247]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = final_model.predict(X_valid)\n",
    "y_prob = final_model.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "print(\"Final F1 Score:\", f1_score(y_valid, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_valid, y_pred))\n",
    "\n",
    "cm = confusion_matrix(y_valid, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save Model & Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ../03_trained_model/catboost_model.cbm\n",
      "Metadata saved to ../03_trained_model/model_metadata.json\n"
     ]
    }
   ],
   "source": [
    "MODEL_DIR = \"../03_trained_model\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "model_path = os.path.join(MODEL_DIR, \"catboost_model.cbm\")\n",
    "final_model.save_model(model_path)\n",
    "print(f\"Model saved to {model_path}\")\n",
    "\n",
    "# 메타데이터 저장\n",
    "metadata = {\n",
    "    \"best_params\": best_params,\n",
    "    \"best_f1_score\": float(study.best_value),\n",
    "    \"feature_names\": FEATURE_COLS,\n",
    "    \"categorical_features\": cat_cols,\n",
    "    \"numerical_features\": num_cols\n",
    "}\n",
    "\n",
    "metadata_path = os.path.join(MODEL_DIR, \"model_metadata.json\")\n",
    "with open(metadata_path, \"w\") as f:\n",
    "    json.dump(metadata, f, indent=4)\n",
    "print(f\"Metadata saved to {metadata_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance saved to ../03_trained_model/feature_importance.csv\n"
     ]
    }
   ],
   "source": [
    "# Feature Importance 저장\n",
    "fi_df = pd.DataFrame({\n",
    "    \"feature\": X_train.columns,\n",
    "    \"importance\": final_model.get_feature_importance()\n",
    "}).sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "fi_path = os.path.join(MODEL_DIR, \"feature_importance.csv\")\n",
    "fi_df.to_csv(fi_path, index=False)\n",
    "print(f\"Feature importance saved to {fi_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-2nd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
